{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca52c308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pywin32 in d:\\code-app\\anaconda\\lib\\site-packages (302)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pywin32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae0e080f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in d:\\code-app\\anaconda\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: pypiwin32 in d:\\code-app\\anaconda\\lib\\site-packages (from pyttsx3) (223)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: comtypes in d:\\code-app\\anaconda\\lib\\site-packages (from pyttsx3) (1.1.10)\n",
      "Requirement already satisfied: pywin32 in d:\\code-app\\anaconda\\lib\\site-packages (from pyttsx3) (302)\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "081fbbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\code-app\\anaconda\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\code-app\\anaconda\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c3936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c70059b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396ad92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\code-app\\anaconda\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy>=1.19.3 in d:\\code-app\\anaconda\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb22fd",
   "metadata": {},
   "source": [
    "Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5687bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a VideoCapture object and read the frames from an input file\n",
    "video = cv2.VideoCapture('Traffic_Laramie_1.mp4')\n",
    " \n",
    "# Check if the video opened successfully\n",
    "if not video.isOpened(): \n",
    "    print(\"Error opening video file\")\n",
    "    exit(0)\n",
    " \n",
    "# create an instance of type K-nearest neighbours background subtraction\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "# define threshold values for detecting objects\n",
    "AREA_THRESHOLD = 500\n",
    "FORM_FACTOR_THRESHOLD = 1.5\n",
    " \n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    check, frame = video.read()\n",
    "    \n",
    "    if not check:\n",
    "        break\n",
    "    \n",
    "    # calculate the foreground mask - this is the frame difference between the original frame and the calculated background\n",
    "    FgMask = backSub.apply(frame)\n",
    "    \n",
    "    # Dilate and erode to get object blobs\n",
    "    FgMask = cv2.dilate(FgMask, None, 18)\n",
    "    FgMask = cv2.erode(FgMask, None, 10)\n",
    "    \n",
    "    # convert the difference (the delta_frame) into a binary image\n",
    "    thresholdFrame = cv2.threshold(FgMask, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # identify all the contours in the binary image\n",
    "    contours, _ = cv2.findContours(thresholdFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # iterate through each contour to identify and draw a bounding box around objects of interest\n",
    "    for c in contours:\n",
    "        # calculate the bounding box for the contour\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        # filter out contours with small area and unsuitable form factor\n",
    "        if cv2.contourArea(c) < AREA_THRESHOLD or h/w < FORM_FACTOR_THRESHOLD:\n",
    "            continue\n",
    "        # draw a bounding box around the contour\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 1)\n",
    "    \n",
    "    # show the processed frames on screen\n",
    "    cv2.imshow('Webcam', frame)\n",
    "    cv2.imshow('Threshold Frame', thresholdFrame)\n",
    "    cv2.imshow('FG Mask', FgMask)\n",
    "    \n",
    "    # press 'q' to exit the program\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    " \n",
    "# release the video object and destroy all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624ff84",
   "metadata": {},
   "source": [
    "Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991d8ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ba8a560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars per minute: 4.76\n",
      "Total number of cars: 6\n"
     ]
    }
   ],
   "source": [
    "# Establish a VideoCapture object and read frames from an input file.\n",
    "vd = cv2.VideoCapture('Traffic_Laramie_1.mp4')\n",
    "\n",
    "# record the video's frame rate in seconds. used to determine the exact number of automobiles per second\n",
    "fr_per_sc = vd.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Verify that the video has properly opened.\n",
    "if not vd.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit(0)\n",
    "\n",
    "# construct a K-nearest Neighbors Background Subtraction object.\n",
    "backSub = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "# keeping the bound boxes from the previous frame\n",
    "prev_bounded_boxes = []\n",
    "\n",
    "# values used to match the current frame's bounding boxes to those from the previous frame\n",
    "# X axis\n",
    "dlt_posX = 10\n",
    "# Y axis\n",
    "dlt_posY = 10\n",
    "# horizontal size\n",
    "dlt_size_hor = 10\n",
    "# vertical size\n",
    "dlt_size_wid = 10\n",
    "\n",
    "# criterion that determines whether a sliding left-bounding box counts\n",
    "x_thre = 200\n",
    "# that establishes the minimum number of frames the bounding box must be monitored along before being counted\n",
    "no_of_frames_thre = 10\n",
    "\n",
    "# amount of vehicles moving toward the city center each minute\n",
    "Cars_per_min = 0\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# counted automobiles in number\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Observe the motions of the bounding boxes.\n",
    "class bounded_box_movement:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        # initialising x axis\n",
    "        self.x = x\n",
    "        # initialising y axis\n",
    "        self.y = y\n",
    "        # initialising width\n",
    "        self.w = w\n",
    "        # initialising height\n",
    "        self.h = h\n",
    "        # direction of movement\n",
    "        self.direction = ''\n",
    "        # if the box has been counted already\n",
    "        self.counted = False\n",
    "        # the amount of frames over which the bounding box has been monitored\n",
    "        self.no_of_frames = 0\n",
    "\n",
    "\n",
    "# Read through the entire video till we press \"q\"\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    # Keep in mind that VideoCapture takes video frames without taking the video's frame rate into account.\n",
    "    check, frame = vd.read()\n",
    "\n",
    "    if check == False:\n",
    "        break;\n",
    "\n",
    "    # the frame difference between the actual frame and the estimated backdrop is the foreground mask.\n",
    "    FgMask = backSub.apply(frame)\n",
    "\n",
    "    # To obtain object blobs, dilate and erode.\n",
    "    FgMask = cv2.dilate(FgMask, None, 18)\n",
    "    FgMask = cv2.erode(FgMask, None, 10)\n",
    "\n",
    "    # The delta frame difference is transformed into a binary picture.\n",
    "    # If a certain pixel value exceeds a specific threshold (specified by us here as 150),\n",
    "    # If White (255) is specified, then Black will be assigned to it (0)\n",
    "    # Important: To get the best performance from your camera, the lighting in your space, etc., you might need to adjust the threshold setting.\n",
    "    ThreFrame = cv2.threshold(FgMask, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # All of the contours in our image will be found using the cv2.findContours() technique.\n",
    "    # Three parameters are required for this method: a picture, a contour retrieval mode, and\n",
    "    # (c) the method of contour approximation\n",
    "    contours, _ = cv2.findContours(ThreFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    # Identified bounding boxes in the current frame\n",
    "    current_bounded_boxes = []\n",
    "    \n",
    "    for c in contours:\n",
    "        # Any tiny contours are removed using the contourArea() function.\n",
    "        (x, y, w, h)=cv2.boundingRect(c)\n",
    "        # with a form factor that recognizes human forms, filter out contours.\n",
    "        if (h/w > 1.5)  | (cv2.contourArea(c) < 500):\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,0,255), 1)\n",
    "        # Bounding box instances should be created in new instances and added to the collection.\n",
    "        current_bounded_boxes.append(bounded_box_movement(x, y, w, h))\n",
    "    \n",
    "    # according to each BBox in current_bounded_boxes\n",
    "    # Verify if it was present in prev_bounded_boxes\n",
    "    # if so, determine the direction of movement and record it.\n",
    "    # if not, it is a new BBox.\n",
    "    # if a bounded Box goes out of screen on the left, increase counter.\n",
    "    \n",
    "    for current_bounded_box in current_bounded_boxes:\n",
    "        fd = False \n",
    "        \n",
    "        for prev_bounded_box in prev_bounded_boxes:\n",
    "            \n",
    "            # bounding box separation from the previous to the current frame\n",
    "            dlt_X = current_bounded_box.x - prev_bounded_box.x\n",
    "            dlt_Y = current_bounded_box.y - prev_bounded_box.y\n",
    "            \n",
    "            # different sizes between the previous and current frames\n",
    "            dlt_W = current_bounded_box.w - prev_bounded_box.w\n",
    "            dlt_H = current_bounded_box.h - prev_bounded_box.h\n",
    "            \n",
    "            # The current bounded box is too remote from the preceding box and is regarded different if this criterion is false.\n",
    "            if (abs(dlt_X) > dlt_posX) | (abs(dlt_Y) > dlt_posY) \\\n",
    "                | (abs(dlt_W) > dlt_size_wid) |  (abs(dlt_H) > dlt_size_hor):\n",
    "                continue\n",
    "                \n",
    "            # That is a match if we are present.\n",
    "            fd = True\n",
    "                       \n",
    "\n",
    "            # determine the direction on X axis.\n",
    "            if dlt_X > 0:\n",
    "                current_bounded_box.direction = 'right'\n",
    "            elif dlt_X < 0:\n",
    "                current_bounded_box.direction = 'left'\n",
    "                current_bounded_box.no_of_frames = prev_bounded_box.no_of_frames + 1\n",
    "            else:\n",
    "                current_bounded_box.direction = ''\n",
    "\n",
    "            # preserves counted bboxes in order from frame to frame\n",
    "            current_bounded_box.counted = prev_bounded_box.counted\n",
    "                \n",
    "                \n",
    "            # leaving the frame\n",
    "            if (current_bounded_box.x < x_thre) and (current_bounded_box.no_of_frames > no_of_frames_thre) \\\n",
    "                and (current_bounded_box.direction == 'left') and (current_bounded_box.counted == False):\n",
    "                #this is a match\n",
    "                counter+=1\n",
    "                current_bounded_box.counted = True\n",
    "                \n",
    "        # Skip the remaining boxes if the prior one is discovered.        \n",
    "        if fd == True:\n",
    "            continue\n",
    "\n",
    "    # the difference in time between the first frame of the video and the current frame\n",
    "    deltaTime = datetime.now() - start_time \n",
    "    # amount of seconds since the start\n",
    "    secs = deltaTime.total_seconds()\n",
    "    # amount of vehicles found each minute\n",
    "    Cars_per_min = counter * 60 / secs\n",
    "    \n",
    "    # get info on screen\n",
    "    # draw rectangle using opencv library\n",
    "    cv2.rectangle(frame,(0,0),(590,65),(255,255,255),-1)\n",
    "    cv2.putText(frame, f'Count:{counter} in {int(secs)}s-({Cars_per_min:.2f} cars/min)', (10, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "    #amount of vehicles found each minute\n",
    "    prev_bounded_boxes = current_bounded_boxes\n",
    "\n",
    "    \n",
    "    #Show frames on screen\n",
    "    if check == True:\n",
    "        cv2.imshow('Webcam', frame)  \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "# printing cars per minute\n",
    "print(f'Cars per minute: {Cars_per_min:.2f}')\n",
    "# printing total nio.of cars\n",
    "print(f'Total number of cars: {counter}')\n",
    "\n",
    "# Releasing the video object after the loop\n",
    "vd.release()\n",
    "\n",
    "# Delete all the windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a834ed",
   "metadata": {},
   "source": [
    "### Try again for testing video 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c30447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cars per minute: 7.03\n",
      "Total number of cars: 5\n"
     ]
    }
   ],
   "source": [
    "# Establish a VideoCapture object and read frames from an input file.\n",
    "vd = cv2.VideoCapture('Traffic_Laramie_2.mp4')\n",
    "\n",
    "# record the video's frame rate in seconds. used to determine the exact number of automobiles per second\n",
    "fr_per_sc = vd.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Verify that the video has properly opened.\n",
    "if not vd.isOpened():\n",
    "    print(\"Error opening video file\")\n",
    "    exit(0)\n",
    "\n",
    "# construct a K-nearest Neighbors Background Subtraction object.\n",
    "backSub = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "# keeping the bound boxes from the previous frame\n",
    "prev_bounded_boxes = []\n",
    "\n",
    "# values used to match the current frame's bounding boxes to those from the previous frame\n",
    "# X axis\n",
    "dlt_posX = 10\n",
    "# Y axis\n",
    "dlt_posY = 10\n",
    "# horizontal size\n",
    "dlt_size_hor = 10\n",
    "# vertical size\n",
    "dlt_size_wid = 10\n",
    "\n",
    "# criterion that determines whether a sliding left-bounding box counts\n",
    "x_thre = 200\n",
    "# that establishes the minimum number of frames the bounding box must be monitored along before being counted\n",
    "no_of_frames_thre = 10\n",
    "\n",
    "# amount of vehicles moving toward the city center each minute\n",
    "Cars_per_min = 0\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# counted automobiles in number\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Observe the motions of the bounding boxes.\n",
    "class bounded_box_movement:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        # initialising x axis\n",
    "        self.x = x\n",
    "        # initialising y axis\n",
    "        self.y = y\n",
    "        # initialising width\n",
    "        self.w = w\n",
    "        # initialising height\n",
    "        self.h = h\n",
    "        # direction of movement\n",
    "        self.direction = ''\n",
    "        # if the box has been counted already\n",
    "        self.counted = False\n",
    "        # the amount of frames over which the bounding box has been monitored\n",
    "        self.no_of_frames = 0\n",
    "\n",
    "\n",
    "# Read through the entire video till we press \"q\"\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    # Keep in mind that VideoCapture takes video frames without taking the video's frame rate into account.\n",
    "    check, frame = vd.read()\n",
    "\n",
    "    if check == False:\n",
    "        break;\n",
    "\n",
    "    # the frame difference between the actual frame and the estimated backdrop is the foreground mask.\n",
    "    FgMask = backSub.apply(frame)\n",
    "\n",
    "    # To obtain object blobs, dilate and erode.\n",
    "    FgMask = cv2.dilate(FgMask, None, 18)\n",
    "    FgMask = cv2.erode(FgMask, None, 10)\n",
    "\n",
    "    # The delta frame difference is transformed into a binary picture.\n",
    "    # If a certain pixel value exceeds a specific threshold (specified by us here as 150),\n",
    "    # If White (255) is specified, then Black will be assigned to it (0)\n",
    "    # Important: To get the best performance from your camera, the lighting in your space, etc., you might need to adjust the threshold setting.\n",
    "    ThreFrame = cv2.threshold(FgMask, 100, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # All of the contours in our image will be found using the cv2.findContours() technique.\n",
    "    # Three parameters are required for this method: a picture, a contour retrieval mode, and\n",
    "    # (c) the method of contour approximation\n",
    "    contours, _ = cv2.findContours(ThreFrame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "    # Identified bounding boxes in the current frame\n",
    "    current_bounded_boxes = []\n",
    "    \n",
    "    for c in contours:\n",
    "        # Any tiny contours are removed using the contourArea() function.\n",
    "        (x, y, w, h)=cv2.boundingRect(c)\n",
    "        # with a form factor that recognizes human forms, filter out contours.\n",
    "        if (h/w > 1.5)  | (cv2.contourArea(c) < 500):\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0,0,255), 1)\n",
    "        # Bounding box instances should be created in new instances and added to the collection.\n",
    "        current_bounded_boxes.append(bounded_box_movement(x, y, w, h))\n",
    "    \n",
    "    # according to each BBox in current_bounded_boxes\n",
    "    # Verify if it was present in prev_bounded_boxes\n",
    "    # if so, determine the direction of movement and record it.\n",
    "    # if not, it is a new BBox.\n",
    "    # if a bounded Box goes out of screen on the left, increase counter.\n",
    "    \n",
    "    for current_bounded_box in current_bounded_boxes:\n",
    "        fd = False \n",
    "        \n",
    "        for prev_bounded_box in prev_bounded_boxes:\n",
    "            \n",
    "            # bounding box separation from the previous to the current frame\n",
    "            dlt_X = current_bounded_box.x - prev_bounded_box.x\n",
    "            dlt_Y = current_bounded_box.y - prev_bounded_box.y\n",
    "            \n",
    "            # different sizes between the previous and current frames\n",
    "            dlt_W = current_bounded_box.w - prev_bounded_box.w\n",
    "            dlt_H = current_bounded_box.h - prev_bounded_box.h\n",
    "            \n",
    "            # The current bounded box is too remote from the preceding box and is regarded different if this criterion is false.\n",
    "            if (abs(dlt_X) > dlt_posX) | (abs(dlt_Y) > dlt_posY) \\\n",
    "                | (abs(dlt_W) > dlt_size_wid) |  (abs(dlt_H) > dlt_size_hor):\n",
    "                continue\n",
    "                \n",
    "            # That is a match if we are present.\n",
    "            fd = True\n",
    "                       \n",
    "\n",
    "            # determine the direction on X axis.\n",
    "            if dlt_X > 0:\n",
    "                current_bounded_box.direction = 'right'\n",
    "            elif dlt_X < 0:\n",
    "                current_bounded_box.direction = 'left'\n",
    "                current_bounded_box.no_of_frames = prev_bounded_box.no_of_frames + 1\n",
    "            else:\n",
    "                current_bounded_box.direction = ''\n",
    "\n",
    "            # preserves counted bboxes in order from frame to frame\n",
    "            current_bounded_box.counted = prev_bounded_box.counted\n",
    "                \n",
    "                \n",
    "            # leaving the frame\n",
    "            if (current_bounded_box.x < x_thre) and (current_bounded_box.no_of_frames > no_of_frames_thre) \\\n",
    "                and (current_bounded_box.direction == 'left') and (current_bounded_box.counted == False):\n",
    "                #this is a match\n",
    "                counter+=1\n",
    "                current_bounded_box.counted = True\n",
    "                \n",
    "        # Skip the remaining boxes if the prior one is discovered.        \n",
    "        if fd == True:\n",
    "            continue\n",
    "\n",
    "    # the difference in time between the first frame of the video and the current frame\n",
    "    deltaTime = datetime.now() - start_time \n",
    "    # amount of seconds since the start\n",
    "    secs = deltaTime.total_seconds()\n",
    "    # amount of vehicles found each minute\n",
    "    Cars_per_min = counter * 60 / secs\n",
    "    \n",
    "    # get info on screen\n",
    "    # draw rectangle using opencv library\n",
    "    cv2.rectangle(frame,(0,0),(590,65),(255,255,255),-1)\n",
    "    cv2.putText(frame, f'Count:{counter} in {int(secs)}s-({Cars_per_min:.2f} cars/min)', (10, 40), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    \n",
    "    #amount of vehicles found each minute\n",
    "    prev_bounded_boxes = current_bounded_boxes\n",
    "\n",
    "    \n",
    "    #Show frames on screen\n",
    "    if check == True:\n",
    "        cv2.imshow('Webcam', frame)  \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "\n",
    "# printing cars per minute\n",
    "print(f'Cars per minute: {Cars_per_min:.2f}')\n",
    "# printing total nio.of cars\n",
    "print(f'Total number of cars: {counter}')\n",
    "\n",
    "# Releasing the video object after the loop\n",
    "vd.release()\n",
    "\n",
    "# Delete all the windows.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6d33e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
